# Sweep Configuration for NICE Model Training

# Default components for sweep training
defaults:
  - dataset: eeg_dataset
  - model: nice_model
  - trainer: nice_trainer
  - encoder: eeg_encoder
  - _self_

# Script-specific settings
script_name: sweep
description: "Parameter sweep for NICE model training"

# Sweep configuration
sweep:
  # Sweep type: random, grid, bayesian, lr, architecture
  type: random
  
  # Number of runs to execute
  count: 10
  
  # Wandb settings
  project: brain-image-nice
  entity: null  # Set to your wandb username or team name
  
  # Metric to optimize
  metric:
    name: val_loss
    goal: minimize
  
  # Early termination
  early_terminate:
    type: hyperband
    min_iter: 10
  
  # Parameter configurations for different sweep types
  parameters:
    random:
      trainer.num_epochs:
        min: 50
        max: 200
        distribution: int_uniform
      model.encoder_lr:
        min: 1e-4
        max: 1e-2
        distribution: log_uniform
      model.projector_lr:
        min: 1e-4
        max: 1e-2
        distribution: log_uniform
      model.temperature_init:
        min: 1.5
        max: 3.5
        distribution: uniform
      model.project_dim:
        values: [128, 256, 512]
      trainer.precision:
        values: [16, 32]
    
    grid:
      trainer.num_epochs:
        values: [50, 100, 150]
      model.encoder_lr:
        values: [1e-3, 5e-3, 8e-3, 1e-2]
      model.projector_lr:
        values: [1e-3, 5e-3, 8e-3, 1e-2]
      model.temperature_init:
        values: [2.0, 2.659260, 3.0]
      trainer.precision:
        values: [16, 32]
    
    bayesian:
      trainer.num_epochs:
        min: 50
        max: 200
        distribution: int_uniform
      model.encoder_lr:
        min: 1e-4
        max: 1e-2
        distribution: log_uniform
      model.projector_lr:
        min: 1e-4
        max: 1e-2
        distribution: log_uniform
      model.temperature_init:
        min: 1.5
        max: 3.5
        distribution: uniform
      model.project_dim:
        values: [128, 256, 512]
      trainer.precision:
        values: [16, 32]
    
    lr:
      model.encoder_lr:
        values: [1e-4, 5e-4, 1e-3, 5e-3, 8e-3, 1e-2, 2e-2]
      model.projector_lr:
        values: [1e-4, 5e-4, 1e-3, 5e-3, 8e-3, 1e-2, 2e-2]
      model.encoder_min_lr:
        values: [1e-5, 1e-4, 5e-4]
      model.projector_min_lr:
        values: [1e-5, 1e-4, 5e-4]
    
    architecture:
      model.project_dim:
        values: [128, 256, 512, 1024]
      model.img_latent_dim:
        values: [512, 768, 1024]
      model.temperature_init:
        values: [2.0, 2.659260, 3.0, 3.5]
      trainer.precision:
        values: [16, 32] 