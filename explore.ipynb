{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c7bba07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import Literal\n",
    "import torchvision\n",
    "from torchvision.transforms import v2 as tv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32390453",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f489ae42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['preprocessed_eeg_data', 'ch_names', 'times'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = Path(\"data\")\n",
    "imgs_dir = data_dir / \"things-eeg2-imgs\"\n",
    "eeg_dir = data_dir / \"things-eeg2-pre\"\n",
    "\n",
    "\n",
    "ex_data_path = \"data/things-eeg2-pre/sub-01/preprocessed_eeg_training.npy\"\n",
    "ex_data = np.load(ex_data_path, allow_pickle=True).item()\n",
    "ex_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d122658",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_paths = [\n",
    "    img_dir\n",
    "    for concept_dir in sorted((imgs_dir / \"training_images\").iterdir())\n",
    "    for img_dir in sorted(concept_dir.iterdir())\n",
    "]\n",
    "test_img_paths = [\n",
    "    img_dir\n",
    "    for concept_dir in sorted((imgs_dir / \"test_images\").iterdir())\n",
    "    for img_dir in sorted(concept_dir.iterdir())\n",
    "]\n",
    "\n",
    "train_imgs_per_concept = 10\n",
    "test_imgs_per_concept = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3270662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 data/things-eeg2-imgs/training_images/00001_aardvark/aardvark_01b.jpg\n",
      "10 data/things-eeg2-imgs/training_images/00002_abacus/abacus_01b.jpg\n",
      "11 data/things-eeg2-imgs/training_images/00002_abacus/abacus_02s.jpg\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def idx_to_img_path(idx: int, split: Literal[\"train\", \"test\"]) -> Path:\n",
    "    if split == \"train\":\n",
    "        paths = train_img_paths\n",
    "\n",
    "    elif split == \"test\":\n",
    "        paths = test_img_paths\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid split: {split}\")\n",
    "\n",
    "    return paths[idx]\n",
    "\n",
    "\n",
    "print(\"0\", idx_to_img_path(0, \"train\"))  # Aardvark 1\n",
    "print(\"10\", idx_to_img_path(10, \"train\"))  # Acabus 1\n",
    "print(\"11\", idx_to_img_path(11, \"train\"))  # Acabus 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2294e65c",
   "metadata": {},
   "source": [
    "## EEG Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e0de24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channel names: Pz, P3, P7, O1, Oz, O2, P4, P8, P1, P5, PO7, PO3, POz, PO4, PO8, P6, P2\n",
      "EEG data: \n",
      "\tShape: (16540, 4, 17, 100)\n",
      "\tData type: float64\n",
      "\tMaximum value: 85.14618876376869\n",
      "\tMinimum value: -328.7584416400444\n",
      "\tMean value: -0.03503607400085798\n",
      "\tStandard deviation: 0.8400870602744809\n",
      "Times: [-0.2  -0.19 -0.18 -0.17 -0.16 -0.15 -0.14 -0.13 -0.12 -0.11 -0.1  -0.09\n",
      " -0.08 -0.07 -0.06 -0.05 -0.04 -0.03 -0.02 -0.01  0.    0.01  0.02  0.03\n",
      "  0.04  0.05  0.06  0.07  0.08  0.09  0.1   0.11  0.12  0.13  0.14  0.15\n",
      "  0.16  0.17  0.18  0.19  0.2   0.21  0.22  0.23  0.24  0.25  0.26  0.27\n",
      "  0.28  0.29  0.3   0.31  0.32  0.33  0.34  0.35  0.36  0.37  0.38  0.39\n",
      "  0.4   0.41  0.42  0.43  0.44  0.45  0.46  0.47  0.48  0.49  0.5   0.51\n",
      "  0.52  0.53  0.54  0.55  0.56  0.57  0.58  0.59  0.6   0.61  0.62  0.63\n",
      "  0.64  0.65  0.66  0.67  0.68  0.69  0.7   0.71  0.72  0.73  0.74  0.75\n",
      "  0.76  0.77  0.78  0.79]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "ex_data_path = \"data/things-eeg2/eeg/sub-01/preprocessed_eeg_training.npy\"\n",
    "ex_data = np.load(ex_data_path, allow_pickle=True).item()\n",
    "channel_names = ex_data[\"ch_names\"]\n",
    "print(f\"Channel names: {', '.join(channel_names)}\")\n",
    "\n",
    "eeg_data = ex_data[\"preprocessed_eeg_data\"]\n",
    "print(\"EEG data: \")\n",
    "print(f\"\\tShape: {eeg_data.shape}\")\n",
    "print(f\"\\tData type: {eeg_data.dtype}\")\n",
    "print(f\"\\tMaximum value: {np.max(eeg_data)}\")\n",
    "print(f\"\\tMinimum value: {np.min(eeg_data)}\")\n",
    "print(f\"\\tMean value: {np.mean(eeg_data)}\")\n",
    "print(f\"\\tStandard deviation: {np.std(eeg_data)}\")\n",
    "\n",
    "times = ex_data[\"times\"]\n",
    "print(f\"Times: {times}\")\n",
    "\n",
    "print(type(eeg_data), type(times), type(channel_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2214d38c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16540, 17, 100)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_eeg_data(eeg_data):\n",
    "    \"\"\"Preprocess the EEG data by averaging over the number of repetitions.\n",
    "\n",
    "    Args:\n",
    "        eeg_data (numpy.ndarray): The EEG data to preprocess. <concepts, repetitions, channels, timesteps>\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: The preprocessed EEG data. <concepts, channels, timesteps>\n",
    "    \"\"\"\n",
    "    # Average over the number of repetitions\n",
    "    preprocessed_data = np.mean(eeg_data, axis=1).astype(np.float32)\n",
    "    return preprocessed_data\n",
    "\n",
    "\n",
    "eeg_data_pp = preprocess_eeg_data(eeg_data)\n",
    "eeg_data_pp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "367096f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_eeg_data(eeg_path: Path):\n",
    "    \"\"\"Load EEG data from a given path.\"\"\"\n",
    "    eeg_data = np.load(eeg_path, allow_pickle=True).item()\n",
    "    return (\n",
    "        preprocess_eeg_data(eeg_data[\"preprocessed_eeg_data\"]),\n",
    "        eeg_data[\"times\"],\n",
    "        eeg_data[\"ch_names\"],\n",
    "    )\n",
    "\n",
    "\n",
    "def load_all_eeg_data(\n",
    "    eeg_paths: list[Path],\n",
    ") -> tuple[torch.Tensor, torch.Tensor, list[str]]:\n",
    "    all_eeg_data = []\n",
    "    all_times = None\n",
    "    all_ch_names = []\n",
    "\n",
    "    for eeg_path in eeg_paths:\n",
    "        eeg_data, times, ch_names = load_eeg_data(eeg_path)\n",
    "        all_eeg_data.append(torch.from_numpy(eeg_data))\n",
    "\n",
    "        if all_times is None:\n",
    "            all_times = torch.tensor(times)\n",
    "\n",
    "        if not all_ch_names:\n",
    "            all_ch_names = ch_names\n",
    "\n",
    "    if all_times is None:\n",
    "        all_times = torch.tensor([])\n",
    "\n",
    "    return torch.concat(all_eeg_data), all_times, all_ch_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee55e909",
   "metadata": {},
   "source": [
    "## Unified Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05bdc597",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class EEGDatasetConfig(BaseModel):\n",
    "    data_path: Path = Path(\"data\")\n",
    "    imgs_dir: str = \"things-eeg2-imgs\"\n",
    "    eeg_dir: str = \"things-eeg2-pre\"\n",
    "    imgs_latent_dir: str = \"things-eeg2-imgs-embed\"\n",
    "    train_imgs_per_concept: int = 10\n",
    "    test_imgs_per_concept: int = 1\n",
    "    subs: list[int] = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "\n",
    "\n",
    "class EEGDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        config: EEGDatasetConfig,\n",
    "        split: Literal[\"train\", \"test\"],\n",
    "        model_name: str = \"synclr\",\n",
    "    ):\n",
    "        self.config = config\n",
    "        self.split = split\n",
    "        self.model_name = model_name\n",
    "        self.imgs_per_concepts = (\n",
    "            self.config.train_imgs_per_concept\n",
    "            if split == \"train\"\n",
    "            else self.config.test_imgs_per_concept\n",
    "        )\n",
    "\n",
    "        if split == \"train\":\n",
    "            img_subdir = \"training_images\"\n",
    "            img_embed_name = \"train_embeddings\"\n",
    "            eeg_name = \"preprocessed_eeg_training\"\n",
    "\n",
    "        else:\n",
    "            img_subdir = \"test_images\"\n",
    "            img_embed_name = \"test_embeddings\"\n",
    "            eeg_name = \"preprocessed_eeg_test\"\n",
    "\n",
    "        self.img_paths = [\n",
    "            img_dir\n",
    "            for concept_dir in sorted(\n",
    "                (self.config.data_path / self.config.imgs_dir / img_subdir).iterdir()\n",
    "            )\n",
    "            for img_dir in sorted(concept_dir.iterdir())\n",
    "        ]\n",
    "        self.img_latents = torch.from_numpy(\n",
    "            np.load(\n",
    "                self.config.data_path\n",
    "                / f\"{self.config.imgs_latent_dir}/{model_name}/{img_embed_name}.npy\"\n",
    "            )\n",
    "        ).float()\n",
    "\n",
    "        self.eeg_data_paths = [\n",
    "            self.config.data_path\n",
    "            / self.config.eeg_dir\n",
    "            / f\"sub-{sub:02}\"\n",
    "            / f\"{eeg_name}.npy\"\n",
    "            for sub in self.config.subs\n",
    "        ]\n",
    "        self.eeg_data, self.times, self.ch_names = load_all_eeg_data(\n",
    "            self.eeg_data_paths\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.eeg_data)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        img_idx = idx % (\n",
    "            len(self.img_paths)\n",
    "        )  # EEG has stacked over subs, so we need to find the right sample within the sub\n",
    "\n",
    "        img_path = self.img_paths[img_idx]\n",
    "        img_latent = self.img_latents[img_idx]\n",
    "\n",
    "        eeg_data = self.eeg_data[idx]\n",
    "\n",
    "        return {\n",
    "            \"img_path\": str(img_path),\n",
    "            \"img_latent\": img_latent,\n",
    "            \"eeg_data\": eeg_data,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae0e9017",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import cast\n",
    "from torch.utils.data import random_split\n",
    "from torch import manual_seed\n",
    "\n",
    "config = EEGDatasetConfig()\n",
    "\n",
    "\n",
    "def make_datasets(\n",
    "    config: EEGDatasetConfig,\n",
    "    model: str = \"synclr\",\n",
    "    seed: int = 42,\n",
    "    train_val_split: float = 0.8,\n",
    ") -> tuple[EEGDataset, EEGDataset, EEGDataset]:\n",
    "    train_dataset = EEGDataset(config, split=\"train\", model_name=model)\n",
    "    test_dataset = EEGDataset(config, split=\"test\", model_name=model)\n",
    "\n",
    "    split_rng = manual_seed(seed)\n",
    "    train_dataset, val_dataset = random_split(\n",
    "        train_dataset, [train_val_split, 1 - train_val_split], generator=split_rng\n",
    "    )\n",
    "    train_dataset = cast(EEGDataset, train_dataset)\n",
    "    val_dataset = cast(EEGDataset, val_dataset)\n",
    "    test_dataset = cast(EEGDataset, test_dataset)\n",
    "\n",
    "    return train_dataset, val_dataset, test_dataset\n",
    "\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = make_datasets(\n",
    "    config, model=\"synclr\", seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5d67e1",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca985fff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1440])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adapted from https://github.com/eeyhsong/NICE-EEG\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import einops\n",
    "\n",
    "\n",
    "class EEGEncoderConfig(BaseModel):\n",
    "    embed_dim: int = 40\n",
    "    encoded_dim: int = 1440  # Result of embed dim * final spatial * final temporal\n",
    "    proj_dim: int = 768\n",
    "\n",
    "    temporal_kernel_size: int = 25\n",
    "    spatial_kernel_size: int = 17\n",
    "    temporal_pool_size: int = 41\n",
    "    temporal_stride: int = 1\n",
    "    hidden_dim: int = 40\n",
    "    dropout: float = 0.5\n",
    "\n",
    "\n",
    "class DebugLayer(nn.Module):\n",
    "    def __init__(self, note: str = \"\"):\n",
    "        super(DebugLayer, self).__init__()\n",
    "        self.note = note\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(f\"(debug): {x.shape} - {self.note}\")\n",
    "        return x\n",
    "\n",
    "\n",
    "class PatchEmbedding(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        embed_dim: int,\n",
    "        temporal_kernel_size: int,\n",
    "        spatial_kernel_size: int,\n",
    "        temporal_pool_size: int,\n",
    "        temporal_stride: int,\n",
    "        hidden_dim: int,\n",
    "        dropout: float = 0.5,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.spatiotemporal_conv = nn.Sequential(\n",
    "            nn.Conv2d(1, hidden_dim, kernel_size=(1, temporal_kernel_size)),\n",
    "            nn.Conv2d(\n",
    "                hidden_dim, hidden_dim, kernel_size=(1, temporal_pool_size), stride=(1, temporal_stride), bias=False\n",
    "            ),\n",
    "            nn.BatchNorm2d(hidden_dim),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.Conv2d(hidden_dim, hidden_dim, kernel_size=(spatial_kernel_size, 1), bias=False),\n",
    "            nn.BatchNorm2d(hidden_dim),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "        self.projection = nn.Conv2d(hidden_dim, embed_dim, kernel_size=(1, 1))\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = einops.rearrange(x, \"b s t -> b 1 s t\")\n",
    "        x = self.spatiotemporal_conv(x)\n",
    "        x = self.projection(x)\n",
    "        x = einops.rearrange(x, \"b e (s) (t) -> b (s t) e\")\n",
    "        return x\n",
    "\n",
    "    def jit_compile(self):\n",
    "        # Compile the model for faster inference\n",
    "        self.spatiotemporal_conv = torch.jit.script(self.spatiotemporal_conv)\n",
    "        self.projection = torch.jit.script(self.projection)\n",
    "        return self\n",
    "\n",
    "\n",
    "class EEGEncoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        config: EEGEncoderConfig = EEGEncoderConfig(),\n",
    "    ):\n",
    "        super(EEGEncoder, self).__init__()\n",
    "\n",
    "        self.patch_embedding = PatchEmbedding(\n",
    "            embed_dim=config.embed_dim,\n",
    "            temporal_kernel_size=config.temporal_kernel_size,\n",
    "            spatial_kernel_size=config.spatial_kernel_size,\n",
    "            temporal_pool_size=config.temporal_pool_size,\n",
    "            temporal_stride=config.temporal_stride,\n",
    "            hidden_dim=config.hidden_dim,\n",
    "            dropout=config.dropout,\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.patch_embedding(x)\n",
    "        x = x.flatten(start_dim=1)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def jit_compile(self):\n",
    "        self.patch_embedding = self.patch_embedding.jit_compile()\n",
    "        return self\n",
    "\n",
    "\n",
    "class LatentProjector(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        embed_dim: int = 1440,\n",
    "        proj_dim: int = 768,\n",
    "        dropout: float = 0.5,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.l_proj = nn.Linear(embed_dim, proj_dim)\n",
    "        self.l_inner = nn.Sequential(\n",
    "            nn.GELU(),\n",
    "            nn.Linear(proj_dim, proj_dim),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "        self.norm = nn.LayerNorm(proj_dim)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x_res = x = self.l_proj(x)\n",
    "        x = self.l_inner(x) + x_res\n",
    "        x = self.norm(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "eeg_config = EEGEncoderConfig()\n",
    "eeg_encoder = EEGEncoder(eeg_config).to(device)\n",
    "\n",
    "ex_data = train_dataset[0][\"eeg_data\"].unsqueeze(0).to(device).to(torch.float32)\n",
    "eeg_encoder(ex_data).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "abc5da92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import itertools as it\n",
    "from lightning import LightningModule\n",
    "\n",
    "\n",
    "@torch.jit.script\n",
    "def compute_cross_entropy_loss(sim: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Compute cross-entropy loss.\"\"\"\n",
    "    labels = torch.arange(sim.size(0), device=sim.device)\n",
    "    loss_e = nn.functional.cross_entropy(sim, labels)\n",
    "    loss_i = nn.functional.cross_entropy(sim.T, labels)\n",
    "    loss = (loss_e + loss_i) / 2\n",
    "    return loss\n",
    "\n",
    "@torch.jit.script\n",
    "def compute_similarity(\n",
    "    eeg_latent: torch.Tensor,\n",
    "    img_latent: torch.Tensor,\n",
    "    temperature: torch.Tensor,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"Compute similarity between EEG and image latents.\"\"\"\n",
    "    eeg_latent = nn.functional.normalize(eeg_latent, dim=-1)\n",
    "    img_latent = nn.functional.normalize(img_latent, dim=-1)\n",
    "    sim = (eeg_latent @ img_latent.T) * torch.exp(temperature)\n",
    "    return sim\n",
    "\n",
    "\n",
    "class NICEConfig(BaseModel):\n",
    "    project_dim: int = 256\n",
    "    eeg_latent_dim: int = 1440\n",
    "    img_latent_dim: int = 768\n",
    "\n",
    "    batch_size: int = 256\n",
    "    eval_batch_size: int = 200\n",
    "    encoder_lr: float = 1e-2\n",
    "    projector_lr: float = 5e-3\n",
    "    betas: tuple[float, float] = (0.9, 0.999)\n",
    "    min_lr: float = 2e-4\n",
    "    warmup_epochs: int = 2\n",
    "    max_epochs: int = 400\n",
    "    num_workers: int = 8\n",
    "    temperature_init: float = math.log(1 / 0.07)\n",
    "\n",
    "\n",
    "class NICEModel(LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        eeg_config: EEGEncoderConfig | None = EEGEncoderConfig(),\n",
    "        eeg_projector: LatentProjector | None = None,\n",
    "        img_projector: LatentProjector | None = None,\n",
    "        config: NICEConfig = NICEConfig(),\n",
    "        dataset_config: EEGDatasetConfig = EEGDatasetConfig(),\n",
    "        model_name: str = \"synclr\",\n",
    "        data_seed: int = 42,\n",
    "        eeg_encoder: EEGEncoder | None = None,\n",
    "        compile: bool = True,\n",
    "        init_weights: bool = True\n",
    "    ):\n",
    "        super(NICEModel, self).__init__()\n",
    "\n",
    "        assert (\n",
    "            eeg_config or eeg_encoder\n",
    "        ), \"Either eeg_config or eeg_encoder must be provided.\"\n",
    "\n",
    "        self.config = config\n",
    "        self.eeg_encoder = eeg_encoder or EEGEncoder(eeg_config)  # type: ignore #\n",
    "        self.eeg_projector = eeg_projector or LatentProjector(\n",
    "            embed_dim=config.eeg_latent_dim,\n",
    "            proj_dim=config.project_dim,\n",
    "        )\n",
    "        self.img_projector = img_projector or LatentProjector(\n",
    "            embed_dim=config.img_latent_dim,\n",
    "            proj_dim=config.project_dim,\n",
    "        )\n",
    "        self.temperature = nn.Parameter(\n",
    "            torch.tensor(config.temperature_init, dtype=torch.float32)\n",
    "        )\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "\n",
    "        if init_weights:\n",
    "            self._init_normal_weights()\n",
    "\n",
    "        self.train_dataset, self.val_dataset, self.test_dataset = make_datasets(\n",
    "            dataset_config,\n",
    "            model=model_name,\n",
    "            seed=data_seed,\n",
    "        )\n",
    "        self.model_name = model_name\n",
    "\n",
    "        if compile:\n",
    "            self.eeg_encoder = self.eeg_encoder.jit_compile()   # type: ignore\n",
    "            self.eeg_projector = torch.jit.script(self.eeg_projector)\n",
    "            self.img_projector = torch.jit.script(self.img_projector)\n",
    "\n",
    "        self.save_hyperparameters(\n",
    "            \"eeg_encoder\",\n",
    "            \"eeg_projector\",\n",
    "            \"img_projector\",\n",
    "            \"config\",\n",
    "            \"dataset_config\",\n",
    "            \"model_name\",\n",
    "            \"data_seed\",\n",
    "        )\n",
    "\n",
    "    def _init_normal_weights(self):\n",
    "        \"\"\"Initialize weights for the model.\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, mean=0.0, std=0.02)\n",
    "            elif isinstance(m, nn.Conv2d):\n",
    "                nn.init.normal_(m.weight, mean=0.0, std=0.02)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.normal_(m.weight, mean=1.0, std=0.02)\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"Configure optimizers for the model.\"\"\"\n",
    "        optimizer = torch.optim.Adam(\n",
    "            [\n",
    "                {\"params\": self.eeg_encoder.parameters(), \"lr\": self.config.encoder_lr},\n",
    "                {\n",
    "                    \"params\": it.chain(\n",
    "                        self.eeg_projector.parameters(),\n",
    "                        self.img_projector.parameters(),\n",
    "                        [self.temperature],\n",
    "                    ),\n",
    "                    \"lr\": self.config.projector_lr,\n",
    "                },\n",
    "            ],\n",
    "            betas=self.config.betas,\n",
    "        )\n",
    "\n",
    "        scheduler = torch.optim.lr_scheduler.SequentialLR(\n",
    "            optimizer,\n",
    "            schedulers=[\n",
    "                torch.optim.lr_scheduler.LinearLR(optimizer, start_factor=0.1, total_iters=self.config.warmup_epochs),\n",
    "                torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=self.config.max_epochs, eta_min=self.config.min_lr),\n",
    "            ],\n",
    "            milestones=[self.config.warmup_epochs],\n",
    "        )\n",
    "        return [optimizer], [scheduler]  \n",
    "\n",
    "    def train_dataloader(self):\n",
    "        \"\"\"Return the training dataloader.\"\"\"\n",
    "        return (\n",
    "            torch.utils.data.DataLoader(\n",
    "                self.train_dataset,\n",
    "                batch_size=self.config.batch_size,\n",
    "                shuffle=True,\n",
    "                num_workers=self.config.num_workers,\n",
    "                pin_memory=True,\n",
    "                persistent_workers=True,\n",
    "            )\n",
    "            if self.train_dataset\n",
    "            else None\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        \"\"\"Return the validation dataloader.\"\"\"\n",
    "        return (\n",
    "            torch.utils.data.DataLoader(\n",
    "                self.val_dataset,\n",
    "                batch_size=self.config.eval_batch_size,\n",
    "                shuffle=False,\n",
    "                num_workers=self.config.num_workers,\n",
    "                pin_memory=True,\n",
    "                persistent_workers=True,\n",
    "            )\n",
    "            if self.val_dataset\n",
    "            else None\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        \"\"\"Return the test dataloader.\"\"\"\n",
    "        return (\n",
    "            torch.utils.data.DataLoader(\n",
    "                self.test_dataset,\n",
    "                batch_size=self.config.eval_batch_size,\n",
    "                shuffle=False,\n",
    "                num_workers=self.config.num_workers,\n",
    "                pin_memory=True,\n",
    "                persistent_workers=True,\n",
    "            )\n",
    "            if self.test_dataset\n",
    "            else None\n",
    "        )\n",
    "\n",
    "    def forward(self, img_latent: torch.Tensor, eeg_data: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward pass through the model.\"\"\"\n",
    "        eeg_latent = self.eeg_encoder(eeg_data)\n",
    "        eeg_latent = self.eeg_projector(eeg_latent)\n",
    "        img_latent = self.img_projector(img_latent)\n",
    "\n",
    "        sim = compute_similarity(\n",
    "            eeg_latent=eeg_latent,\n",
    "            img_latent=img_latent,\n",
    "            temperature=self.temperature,\n",
    "        )\n",
    "\n",
    "        return sim\n",
    "\n",
    "    def get_loss(self, sim: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Compute cross-entropy loss.\"\"\"\n",
    "        loss = compute_cross_entropy_loss(sim)\n",
    "        return loss\n",
    "\n",
    "    def get_top_n_accuracy(self, sim: torch.Tensor, n: int = 1) -> float:\n",
    "        \"\"\"Compute top-n accuracy.\"\"\"\n",
    "        labels = torch.arange(sim.size(0), device=sim.device)\n",
    "        top_n = sim.topk(n, dim=-1).indices\n",
    "\n",
    "        correct = top_n == labels.unsqueeze(1)\n",
    "        return (correct.any(dim=-1).float().sum() / correct.size(0)).item()\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \"\"\"Training step for the model.\"\"\"\n",
    "        img_latent = batch[\"img_latent\"]\n",
    "        eeg_data = batch[\"eeg_data\"]\n",
    "\n",
    "        sim = self(img_latent, eeg_data)\n",
    "        loss = self.get_loss(sim)\n",
    "\n",
    "        self.log(\"train/loss\", loss, prog_bar=True, on_step=True, on_epoch=False)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        img_latent = batch[\"img_latent\"]\n",
    "        eeg_data = batch[\"eeg_data\"]\n",
    "\n",
    "        sim = self(img_latent, eeg_data)\n",
    "        loss = self.get_loss(sim)\n",
    "\n",
    "        top1_acc = self.get_top_n_accuracy(sim, n=1)\n",
    "        top3_acc = self.get_top_n_accuracy(sim, n=3)\n",
    "        top5_acc = self.get_top_n_accuracy(sim, n=5)\n",
    "\n",
    "        self.log(\"val/loss\", loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        self.log(\"val/top1_acc\", top1_acc, prog_bar=False, on_step=False, on_epoch=True)\n",
    "        self.log(\"val/top3_acc\", top3_acc, prog_bar=False, on_step=False, on_epoch=True)\n",
    "        self.log(\"val/top5_acc\", top5_acc, prog_bar=False, on_step=False, on_epoch=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        img_latent = batch[\"img_latent\"]\n",
    "        eeg_data = batch[\"eeg_data\"]\n",
    "\n",
    "        sim = self(img_latent, eeg_data)\n",
    "        loss = self.get_loss(sim)\n",
    "        top1_acc = self.get_top_n_accuracy(sim, n=1)\n",
    "        top3_acc = self.get_top_n_accuracy(sim, n=3)\n",
    "        top5_acc = self.get_top_n_accuracy(sim, n=5)\n",
    "\n",
    "        self.log(\"test/loss\", loss, prog_bar=True, on_step=False, on_epoch=False)\n",
    "        self.log(\"test/top1_acc\", top1_acc, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        self.log(\n",
    "            \"test/top3_acc\", top3_acc, prog_bar=False, on_step=False, on_epoch=True\n",
    "        )\n",
    "        self.log(\n",
    "            \"test/top5_acc\", top5_acc, prog_bar=False, on_step=False, on_epoch=True\n",
    "        )\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e13135",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff06a23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch import Trainer\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, LearningRateMonitor\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "\n",
    "def setup_and_train(\n",
    "    config: NICEConfig = NICEConfig(),\n",
    "    dataset_config: EEGDatasetConfig = EEGDatasetConfig(),\n",
    "    model_name: str = \"synclr\",\n",
    "    data_seed: int = 42,\n",
    "    save_top_k: int = 1,\n",
    "):\n",
    "    torch.set_float32_matmul_precision(\"medium\")\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = NICEModel(\n",
    "        config=config,\n",
    "        dataset_config=dataset_config,\n",
    "        model_name=model_name,\n",
    "        data_seed=data_seed,\n",
    "    )\n",
    "    model.to(device)\n",
    "    \n",
    "\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        monitor=\"val/loss\",\n",
    "        filename=\"checkpoint/{epoch:02d}-{val/loss:.2f}\",\n",
    "        save_top_k=save_top_k,\n",
    "        mode=\"min\",\n",
    "    )\n",
    "\n",
    "    lr_monitor = LearningRateMonitor(logging_interval='step')\n",
    "\n",
    "    logger = TensorBoardLogger(\n",
    "        save_dir=\"logs\",\n",
    "        name=model_name,\n",
    "        default_hp_metric=False,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        max_epochs=config.max_epochs,\n",
    "        callbacks=[checkpoint_callback, lr_monitor],\n",
    "        logger=logger,\n",
    "        enable_progress_bar=True,\n",
    "        accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "    )\n",
    "\n",
    "    trainer.fit(model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31b443d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SYNCLR = False\n",
    "\n",
    "if TRAIN_SYNCLR:\n",
    "    setup_and_train(\n",
    "        model_name=\"synclr\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2fb23a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type                  | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | eeg_encoder   | EEGEncoder            | 95.6 K | train\n",
      "1 | eeg_projector | RecursiveScriptModule | 435 K  | train\n",
      "2 | img_projector | RecursiveScriptModule | 263 K  | train\n",
      "3 | loss          | CrossEntropyLoss      | 0      | train\n",
      "  | other params  | n/a                   | 1      | n/a  \n",
      "----------------------------------------------------------------\n",
      "794 K     Trainable params\n",
      "0         Non-trainable params\n",
      "794 K     Total params\n",
      "3.176     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d6eb7dba9624346bcfce331e23f2ffb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92c4639953f84283821d719aa2a2bd46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa44068cb2a34670a948a2b910ae2f61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c95777c2775244b8b24cf03588552b7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f15a4a217894e868f4b1dbf1f2e9241",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "958b6ad8d3a3423ea6962f41f08b4c5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b747683ae6ca45fd8a6cbebf5dad947d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d601113c75004297b12e954b8b7e3b20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82e6a7bd34744256b870aa2bdb260ef6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d122921f2954d8087944dd6e663f49c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ab9a13e331a4b8aa611eac1b5d419ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "308041623ae744ceb29cd2bf72e4aad1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d78b632c5d6426fabb34c9a90f73404",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ef9c1a037e048f391bf7b5774629f84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83543ed0da8647baae7eb76fb5995ec9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c1478af0c3d4b278bfdc93d718a80f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02d8c45e25794b4093e6d58333d14955",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "399f8cd66ca64647862241224b085552",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2ba2b671f1246179e2929fa53844595",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d92da11d53264ca581f648ce55d94e8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4667e8f9b02044f79deeef058681bb94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4063ae5bc62a4a16b8cc028d70007013",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ffa955171bf4299a98ef5ca86f985ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc3949663cff44159b4f8513f3a1ebfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adb41bee512f4f31a8ccc2db92282b27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dbed8cca41148c696902fbd380babee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a10e169e84974ade8cf80d42cbd91bf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "941609a15711405d9bc43b10883e2d30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7a4123a09e049fcb551489126ca4105",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50102b55b13744a2b4431a0894ca49e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36be86104a2b409d91dc25d31358ab5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc7f9067593348888aa020d62ec2dc32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d705f50839874d2aa747105484e9594f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04123284cebf4cc5b71c7f70432bcdb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d4fabb36bbf4dbabcf0e8f1b255a68b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e78ab2a674f4a448c38b90898d02e7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "014b724d0f04468bb6f8a6cd35d16a40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04376e7298864dba82d946934e21127c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6281609fe7d54e2c9a496fc950c3ab15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3382e1de9d7343e6a50262acc7b15eac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "637ea4862d7b4aaf8d96c623276b8512",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "285267b1905348aa9d33f487a4c78923",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fb62e59b5994eb6af4c6091399c8df3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45bec7a3ea83447cbcce94c405da7bdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ed3511e43084e968899f3390e435dcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "934c6545b80e4ca9baf6004a395f4697",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e24629c6799b44c2a9afa32b28e965c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a42acef1bc0e4868ad80de71c6948bc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e438900c5caf48caa63c3f58abead42c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e94e095fa2ea4369b5992086c6f87669",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0164434d4fe5446b97cbd00f9d9db07b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21b18a7b8b0a4357aceebb10e625d685",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67b0547bd03a4f3ab2a7947921a5c540",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ccf8e7fb96548139c2a65a54609b2ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6db346c9a0e64e00959bacbfd1c9d7ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db0966bf0eed411e8e08b6a72ab5049a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "564e99d96ab14f6081b4dedd9caebd66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aa500beb0b546b3b76099a52cc92c21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "393feb4cef084b5cb744934c08212fa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "674e2bee4a6848a48f283855e419de2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e644b184541d4a5a91dcddba66b7dc9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b83d667f64d4a2098bc9822aeb71cc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "362802bfc80240ba8702e26da96145e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4469d12924d14b23a6da8d2627420c83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7aef4b589f44790ade3555d9d830ece",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8b37048f84b4d2c8fe0c4df55081d26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbbdc0ea7f0c4a8983a2602c5739f375",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82ae8dd05e5f4f988cf999cc2bc63adf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b641b871baed46db9b3f21ab8edac7b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0989c52135b4e479a36587f00b35453",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e49ee9fa23fa4e64a383cbe431b0f681",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebdbeb2b0dac4f239f8b9b4766ea30fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c0aa41e3d0c42b4840adb3ce1961ddb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21051cdce5a7446f8ae027568b9d4cb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e769752be5aa4891a497dd93421b1efc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d10875b726f84feabd8077e9d9124bec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0db650f4a7bf41baada0e97cc72193cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d266d891e7243ad89f995974d93b8f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c9ac76ee99747a2be11f488806f07ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1d57e259a014c428d60064b9464d6a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78878372dcc140b09a33551c3a5808a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d30445cc91e84c8e8c30d75cf20c5fc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89cc3cd507fd4f36914534cbc3f1b432",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e19716c23aad47a6bd655dc751d8738b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25ca3c000c264933b6925198c20241de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecb956c0bec1448ea1b61c582bdc8f97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4654d8e4748e4724a49b34bbfc8d23fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c2763bd1f1f47ebb6cea65f82aa96dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31c4021a2af34b029fc5b15e1696196b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ce68fda098b4953bedd61f7f958c57e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d27c0901d1e24062a87caa02483b7085",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f95d236b84e24ef6bdfba83295461872",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "559c441b81154bba9b73e629b62853e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27191ddc62154c29ad7fa6e080ff8af7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9c774df313c47a1bb49ca59fd8420cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6881ef1b024b46d7a734eccd5950f551",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22600b7ddb37437787233bd65fe4e78f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1354cce44b2c46c6ac975ed6938f3347",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "297e34d1a7bb496e978223838549c195",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de9fd22ff9464510b6e7ac6450340a5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cc93aa72c604fe88f10921e972b7c28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10867694ec7a4105a5d3ccdb1104eda6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe2c141493734e359f4da2570cb5f83d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "165c967e46b0453b9b7b4908837267ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c10edffd6754d17b8868118c23887e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49ba395d598447459b580bb94bf8b688",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/brain-image-implementation/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py:48\u001b[39m, in \u001b[36m_call_and_handle_interrupt\u001b[39m\u001b[34m(trainer, trainer_fn, *args, **kwargs)\u001b[39m\n\u001b[32m     47\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/brain-image-implementation/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py:599\u001b[39m, in \u001b[36mTrainer._fit_impl\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[39m\n\u001b[32m    593\u001b[39m ckpt_path = \u001b[38;5;28mself\u001b[39m._checkpoint_connector._select_ckpt_path(\n\u001b[32m    594\u001b[39m     \u001b[38;5;28mself\u001b[39m.state.fn,\n\u001b[32m    595\u001b[39m     ckpt_path,\n\u001b[32m    596\u001b[39m     model_provided=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    597\u001b[39m     model_connected=\u001b[38;5;28mself\u001b[39m.lightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    598\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m599\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    601\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.stopped\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/brain-image-implementation/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py:1012\u001b[39m, in \u001b[36mTrainer._run\u001b[39m\u001b[34m(self, model, ckpt_path)\u001b[39m\n\u001b[32m   1009\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1010\u001b[39m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[32m   1011\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1012\u001b[39m results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1015\u001b[39m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[32m   1016\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/brain-image-implementation/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py:1056\u001b[39m, in \u001b[36mTrainer._run_stage\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1055\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.autograd.set_detect_anomaly(\u001b[38;5;28mself\u001b[39m._detect_anomaly):\n\u001b[32m-> \u001b[39m\u001b[32m1056\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1057\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/brain-image-implementation/.venv/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py:216\u001b[39m, in \u001b[36m_FitLoop.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;28mself\u001b[39m.on_advance_start()\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28mself\u001b[39m.on_advance_end()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/brain-image-implementation/.venv/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py:455\u001b[39m, in \u001b[36m_FitLoop.advance\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    454\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m455\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mepoch_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/brain-image-implementation/.venv/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py:151\u001b[39m, in \u001b[36m_TrainingEpochLoop.run\u001b[39m\u001b[34m(self, data_fetcher)\u001b[39m\n\u001b[32m    150\u001b[39m     \u001b[38;5;28mself\u001b[39m.advance(data_fetcher)\n\u001b[32m--> \u001b[39m\u001b[32m151\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mon_advance_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/brain-image-implementation/.venv/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py:370\u001b[39m, in \u001b[36m_TrainingEpochLoop.on_advance_end\u001b[39m\u001b[34m(self, data_fetcher)\u001b[39m\n\u001b[32m    368\u001b[39m     call._call_lightning_module_hook(\u001b[38;5;28mself\u001b[39m.trainer, \u001b[33m\"\u001b[39m\u001b[33mon_validation_model_zero_grad\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m370\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mval_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[38;5;28mself\u001b[39m.trainer.training = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/brain-image-implementation/.venv/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py:179\u001b[39m, in \u001b[36m_no_grad_context.<locals>._decorator\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    178\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context_manager():\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/brain-image-implementation/.venv/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py:145\u001b[39m, in \u001b[36m_EvaluationLoop.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    144\u001b[39m     \u001b[38;5;66;03m# run step hooks\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_evaluation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m    147\u001b[39m     \u001b[38;5;66;03m# this needs to wrap the `*_step` call too (not just `next`) for `dataloader_iter` support\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/brain-image-implementation/.venv/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py:437\u001b[39m, in \u001b[36m_EvaluationLoop._evaluation_step\u001b[39m\u001b[34m(self, batch, batch_idx, dataloader_idx, dataloader_iter)\u001b[39m\n\u001b[32m    432\u001b[39m step_args = (\n\u001b[32m    433\u001b[39m     \u001b[38;5;28mself\u001b[39m._build_step_args_from_hook_kwargs(hook_kwargs, hook_name)\n\u001b[32m    434\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_dataloader_iter\n\u001b[32m    435\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m (dataloader_iter,)\n\u001b[32m    436\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m437\u001b[39m output = \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mstep_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    439\u001b[39m \u001b[38;5;28mself\u001b[39m.batch_progress.increment_processed()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/brain-image-implementation/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py:328\u001b[39m, in \u001b[36m_call_strategy_hook\u001b[39m\u001b[34m(trainer, hook_name, *args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m trainer.profiler.profile(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer.strategy.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m     output = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/brain-image-implementation/.venv/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py:412\u001b[39m, in \u001b[36mStrategy.validation_step\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    411\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_redirection(\u001b[38;5;28mself\u001b[39m.model, \u001b[38;5;28mself\u001b[39m.lightning_module, \u001b[33m\"\u001b[39m\u001b[33mvalidation_step\u001b[39m\u001b[33m\"\u001b[39m, *args, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m412\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlightning_module\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 235\u001b[39m, in \u001b[36mNICEModel.validation_step\u001b[39m\u001b[34m(self, batch, batch_idx)\u001b[39m\n\u001b[32m    233\u001b[39m loss = \u001b[38;5;28mself\u001b[39m.get_loss(sim)\n\u001b[32m--> \u001b[39m\u001b[32m235\u001b[39m top1_acc = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_top_n_accuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[43msim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    236\u001b[39m top3_acc = \u001b[38;5;28mself\u001b[39m.get_top_n_accuracy(sim, n=\u001b[32m3\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 215\u001b[39m, in \u001b[36mNICEModel.get_top_n_accuracy\u001b[39m\u001b[34m(self, sim, n)\u001b[39m\n\u001b[32m    214\u001b[39m correct = top_n == labels.unsqueeze(\u001b[32m1\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m215\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m(\u001b[49m\u001b[43mcorrect\u001b[49m\u001b[43m.\u001b[49m\u001b[43many\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[43mcorrect\u001b[49m\u001b[43m.\u001b[49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m TRAIN_ALIGNED_SYNCLR = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m TRAIN_ALIGNED_SYNCLR:\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     \u001b[43msetup_and_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maligned_synclr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 48\u001b[39m, in \u001b[36msetup_and_train\u001b[39m\u001b[34m(config, dataset_config, model_name, data_seed, save_top_k)\u001b[39m\n\u001b[32m     34\u001b[39m logger = TensorBoardLogger(\n\u001b[32m     35\u001b[39m     save_dir=\u001b[33m\"\u001b[39m\u001b[33mlogs\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     36\u001b[39m     name=model_name,\n\u001b[32m     37\u001b[39m     default_hp_metric=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     38\u001b[39m )\n\u001b[32m     40\u001b[39m trainer = Trainer(\n\u001b[32m     41\u001b[39m     max_epochs=config.max_epochs,\n\u001b[32m     42\u001b[39m     callbacks=[checkpoint_callback, lr_monitor],\n\u001b[32m   (...)\u001b[39m\u001b[32m     45\u001b[39m     accelerator=\u001b[33m\"\u001b[39m\u001b[33mgpu\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     46\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/brain-image-implementation/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py:561\u001b[39m, in \u001b[36mTrainer.fit\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[39m\n\u001b[32m    559\u001b[39m \u001b[38;5;28mself\u001b[39m.training = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    560\u001b[39m \u001b[38;5;28mself\u001b[39m.should_stop = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m561\u001b[39m \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    562\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[32m    563\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/brain-image-implementation/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py:65\u001b[39m, in \u001b[36m_call_and_handle_interrupt\u001b[39m\u001b[34m(trainer, trainer_fn, *args, **kwargs)\u001b[39m\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(launcher, _SubprocessScriptLauncher):\n\u001b[32m     64\u001b[39m         launcher.kill(_get_sigkill_signal())\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m     \u001b[43mexit\u001b[49m(\u001b[32m1\u001b[39m)\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[32m     68\u001b[39m     _interrupt(trainer, exception)\n",
      "\u001b[31mNameError\u001b[39m: name 'exit' is not defined"
     ]
    }
   ],
   "source": [
    "TRAIN_ALIGNED_SYNCLR = True\n",
    "\n",
    "if TRAIN_ALIGNED_SYNCLR:\n",
    "    setup_and_train(\n",
    "        model_name=\"aligned_synclr\",\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
